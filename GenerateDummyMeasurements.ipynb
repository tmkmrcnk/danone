{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data will be read from or stored under this folder\n",
    "DATA_DIR = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: generate dummy measurement data\n",
    "- specify the time range (start_time, end_time)\n",
    "- specify frequency in seconds\n",
    "- specify list of measurements names\n",
    "- generate timestamps within the time range with the frequency\n",
    "- for measurement name generate a distribution of measurement values\n",
    "- merge all of the data into a single dataframe and save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(lower=0, upper=1, mean=0.5, stdev=0.1, n=100):\n",
    "    '''\n",
    "    generate normal distribution of size n in (lower,upper) range with a given mean and stdev\n",
    "    '''\n",
    "    return truncnorm.rvs((lower-mean)/stdev, (upper-mean)/stdev, loc=mean, scale=stdev, size=n)\n",
    "\n",
    "\n",
    "def generate_measurements(start_time, end_time, frequency_seconds, names=[\"m1\"]):\n",
    "    '''\n",
    "    generate measurements\n",
    "    '''\n",
    "    # convert start and end times to timestamps\n",
    "    start_time = str2date(start_time)\n",
    "    end_time = str2date(end_time)\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    # generate timestamps for individual measurements between start_time and end_time with frequency in seconds\n",
    "    timestamp2datetime = lambda x: pd.to_datetime(x, unit='s')    \n",
    "    times = [timestamp2date(x) for x in range(nano2sec(start_time.value), nano2sec(end_time.value), frequency_seconds)]\n",
    "    data['timestamp'] = times\n",
    "    \n",
    "    # for each feature generate measurement data from normal distribution\n",
    "    for name in names:\n",
    "        data[name] = normal_dist(lower=0, upper=100, mean=50, stdev=15, n=len(times))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# basic date converters between string (e.g. '2018-01-01 00:00:00'), datetime and unix timestamp\n",
    "str2date = lambda x: pd.Timestamp(x) # string to datetime\n",
    "timestamp2date = lambda x: pd.to_datetime(x, unit='s') # convert unix timestamp to datetime with second resolution\n",
    "nano2sec = lambda x: int(x / 10 ** 9) # convert nanoseconds to seconds\n",
    "str2timestamp = lambda x: nano2sec(str2date(x).value)\n",
    "\n",
    "# time ranges: 1m - 1 month, 1w - 1 week, 1m - 1 month, 1y - 1 year\n",
    "time_ranges = {\n",
    "    '1d': ('2018-01-01 00:00:00', '2018-01-01 23:59:59'),\n",
    "    '1w': ('2018-01-01 00:00:00', '2018-01-07 23:59:59'),\n",
    "    '1m': ('2018-01-01 00:00:00', '2018-01-31 23:59:59'),\n",
    "    '1y': ('2018-01-01 00:00:00', '2018-12-31 23:59:59')}    \n",
    "\n",
    "# specify which time range to use\n",
    "#time_range_key = '1m'\n",
    "time_range_key = '1y'\n",
    "start_time = time_ranges[time_range_key][0]\n",
    "end_time = time_ranges[time_range_key][1]\n",
    "\n",
    "# measurements frequency\n",
    "freq = 30\n",
    "\n",
    "# measurement names\n",
    "names = ['m1', 'm2', 'm3', 'm4', 'm5']\n",
    "\n",
    "# generate measurements\n",
    "measurements = generate_measurements(start_time, end_time, freq, names)\n",
    "\n",
    "# save to file\n",
    "data_file_name = DATA_DIR / F\"measurements-dummy-{time_range_key}.csv\"\n",
    "measurements.to_csv(data_file_name, index=False)\n",
    "\n",
    "measurements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.describe(percentiles=[.1, .25, 0.5, .75, .9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of m1\n",
    "sns.distplot(measurements.m1, bins=256)\n",
    "\n",
    "# plot correlations\n",
    "#sns.pairplot(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: generate production data\n",
    "- specify a time interval (start_time, end_time)\n",
    "- generate N production events each with an end_time and duration of 1.5h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_min_distance(min_value=10, max_value=150, size=10, dist=15):\n",
    "    all_values = range(min_value, max_value + 1, dist + 1)\n",
    "    return sorted(np.random.choice(all_values, size=size, replace=False))\n",
    "\n",
    "def generate_production_data(start_time, end_time, prod_count, duration_min=90, feature_names=['f1']):\n",
    "    # convert start and end times to timestamps\n",
    "    start_time = str2date(start_time)\n",
    "    end_time = str2date(end_time)\n",
    "    \n",
    "    data = {}\n",
    "    durarion_sec = duration_min * 60\n",
    "    data['duration'] = duration_min\n",
    "    end_dates = [timestamp2date(x) for x in sample_with_min_distance(nano2sec(start_time.value), nano2sec(end_time.value), size=prod_count, dist=durarion_sec + 1)]\n",
    "    data['finished_time'] = end_dates\n",
    "    for name in feature_names:\n",
    "        data[name] = normal_dist(lower=0, upper=100, mean=50, stdev=30, n=len(end_dates))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# number of production data points to generate\n",
    "\n",
    "# generate production data with prod_count number of data points\n",
    "prod_count = 1000 if time_range_key == '1y' else 100 if time_range_key == '1m' else 100\n",
    "prod_data = generate_production_data(start_time, end_time, prod_count, feature_names=['efficiency'])\n",
    "\n",
    "# save to file as csv\n",
    "data_file_name = DATA_DIR / F\"production-dummy-{prod_count}-{time_range_key}.csv\"\n",
    "prod_data.to_csv(data_file_name, index=False)\n",
    "\n",
    "# plot distribution of m1\n",
    "sns.distplot(prod_data.efficiency, bins=256)\n",
    "\n",
    "prod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_data.describe(percentiles=[.1, .25, 0.5, .75, .9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
